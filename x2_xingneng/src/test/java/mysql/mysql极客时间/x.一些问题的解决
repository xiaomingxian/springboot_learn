1.如何避免长事务对业务的影响？
    这个问题，我们可以从应用开发端和数据库端来看。
    首先，从应用开发端来看：
    确认是否使用了set autocommit=0。这个确认工作可以在测试环境中开展，把MySQL的general_log开起来，然后随便跑一个业务逻辑，通过general_log的日志来确认。一般框架如果会设置这个值，也就会提供参数来控制行为，你的目标就是把它改成1。
    确认是否有不必要的只读事务。有些框架会习惯不管什么语句先用begin/commit框起来。我见过有些是业务并没有这个需要，但是也把好几个select语句放到了事务中。这种只读事务可以去掉。
    业务连接数据库的时候，根据业务本身的预估，通过SET MAX_EXECUTION_TIME命令，来控制每个语句执行的最长时间，避免单个语句意外执行太长时间。（为什么会意外？在后续的文章中会提到这类案例）
    其次，从数据库端来看：
    监控 information_schema.Innodb_trx表，设置长事务阈值，超过就报警/或者kill；
    Percona的pt-kill这个工具不错，推荐使用；
    在业务功能测试阶段要求输出所有的general_log，分析日志行为提前发现问题；
    如果使用的是MySQL 5.6或者更新版本，把innodb_undo_tablespaces设置成2（或更大的值）。如果真的出现大事务导致回滚段过大，这样设置后清理起来更方便。

2.更新频繁的表如何变更表结构(表锁)[场景:表数据备份]
    非InnoDb表(不支持事物):在alter table语句里面 设定等待时间，如果在这个指定的等待时间里面能够拿到MDL写锁最好，拿不到也不要阻塞后 面的业务语句，先放弃。之后开发人员或者DBA再通过重试命令重复这个过程。
    InnoDb:使用–single-transaction参数，对应用会更友好

3.行锁互相等待造成的死锁：
    事物A                                 事物B
    begin;
    update ... where id=1;·

                                        update ... where id=2;

    update ... where id=2;


                                        update ... where id=1;
    解决方案:
        1 进入死锁等待 直到超时 innodb_lock_wait_timeout
        2 发起死锁检测机制 发现死锁后 直接回滚其中的某一条事物让其他事物继续执行 innodb_deadlock_wait on/off

    数据库有检测死锁机制 但是热点数据会有大量的线程并发访问 导致死锁检测的代价很高 大量的消耗CPU 但事物的执行效率很低
        1 技术思路：让线程去等待 在进入引擎前排队 这样innodb就不会大量检测死锁  eg:使用中间件
        2 业务思路：将一条操作拆分成多条 降低冲突概率(A:修改1条数据 此数据用于统计  B:拆分成多条数据,统计时多条数据综合统计)

